{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath('../classes/'))\n",
    "from feature_factory import FeatureFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for FeatureFactory\n",
    "factory = FeatureFactory(train_df, test_df)\n",
    "\n",
    "factory.add_time_features()\n",
    "factory.add_rolling_features(window_size=3)\n",
    "factory.add_ratio_and_diff_features()\n",
    "factory.add_aFRR_activation_request_ratio()\n",
    "factory.add_FRCE_LFCInput_difference()\n",
    "factory.add_participation_state()\n",
    "factory.add_demand_FRCE_interaction()\n",
    "\n",
    "factory.train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "# New features beginn with 'day', ...\n",
    "features = ['Demand', 'correction', 'correctedDemand',\n",
    "       'FRCE', 'controlBandPos', 'controlBandNeg', 'LFCInput',\n",
    "       'aFRRactivation', 'aFRRrequest', 'participationCMO', 'participationIN',\n",
    "       'correctionEcho', 'BandLimitedCorrectedDemand', 'controlArea', 'hour',\n",
    "       'day', 'weekday', 'month', 'Demand_RollingMean', 'Demand_RollingStd',\n",
    "       'Demand_CorrectedDemand_Ratio', 'Demand_CorrectedDemand_Diff',\n",
    "       'aFRR_Activation_Request_Ratio', 'FRCE_LFCInput_Diff',\n",
    "       'Participation_State', 'Demand_FRCE_Interaction']\n",
    "X_train = factory.train_data[features]\n",
    "X_test = factory.test_data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isna().sum()          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train_normalized.shape[1]\n",
    "\n",
    "# Autoencoder model\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(64, activation='relu')(input_layer)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(input_dim, activation='linear')(decoded)\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(X_train_normalized, X_train_normalized, epochs=5, batch_size=128, validation_data=(X_test_normalized, X_test_normalized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed = autoencoder.predict(X_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate reconstruction error\n",
    "mse = np.mean(np.power(X_test_normalized - reconstructed, 2), axis=1)\n",
    "\n",
    "# Define the threshold at 95 %, every over is anomaly\n",
    "threshold = np.percentile(mse, 95)\n",
    "test_df['anomaly'] = mse > threshold\n",
    "\n",
    "# Convert to int\n",
    "test_df['anomaly'] = test_df['anomaly'].astype(int)\n",
    "print(test_df[['Datum_Uhrzeit_CET', 'Demand', 'correctedDemand', 'anomaly']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission file\n",
    "submission_df = test_df[['id', 'anomaly']]\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ai Serving Grid Stability",
   "language": "python",
   "name": "ai-serving-grid-stab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
