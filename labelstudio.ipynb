{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X GET https://data-science-kitchen-labelstudio.hf.space/ -H 'Authorization: Token b26bd6be6a16e42663f9de0ad0d782b673ece82b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from label_studio_sdk import Client\n",
    "\n",
    "LABEL_STUDIO_URL = 'https://data-science-kitchen-labelstudio.hf.space'\n",
    "API_KEY = 'b26bd6be6a16e42663f9de0ad0d782b673ece82b'\n",
    "\n",
    "ls = Client(url=LABEL_STUDIO_URL, api_key=API_KEY)\n",
    "ls.check_connection()\n",
    "project = ls.get_project(1)\n",
    "task_ids = project.get_tasks_ids()\n",
    "# Examplen to get the CSV file path\n",
    "project.get_task(task_ids[0])['data']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_anomalies(df, window_size=4, threshold=2, loops=2):\n",
    "    count = 0\n",
    "    for l in range(loops):\n",
    "        for index, row in df.iterrows():\n",
    "            if row[\"anomaly\"] == 0:\n",
    "                start_index = max(index - window_size, 0)\n",
    "                end_index = min(index + window_size + 1, len(df))\n",
    "                window = df[\"anomaly\"][start_index:end_index]\n",
    "\n",
    "                # Pr端fe, ob mindestens eine '1' im Bereich vor und nach der '0' ist\n",
    "                if 1 in df[\"anomaly\"][start_index:index].values and 1 in df[\"anomaly\"][index + 1: end_index].values:\n",
    "                    window = df[\"anomaly\"][start_index:end_index]\n",
    "                    if window.sum() >= threshold:\n",
    "                        df.at[index, \"anomaly\"] = 1\n",
    "                        count += 1\n",
    "    print(\"Gef端llt:\", count)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_anomalies(df, window_size=5, threshold=1):\n",
    "    count = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if row[\"anomaly\"] == 1:\n",
    "            start_index = max(index - window_size, 0)\n",
    "            end_index = min(index + window_size + 1, len(df))\n",
    "\n",
    "            if 0 in df[\"anomaly\"][start_index:index].values and 0 in df[\"anomaly\"][index + 1: end_index].values:\n",
    "                window = df[\"anomaly\"][start_index:end_index]\n",
    "                if window.sum() <= threshold:\n",
    "                    df.at[index, \"anomaly\"] = 0\n",
    "                    count += 1\n",
    "    print(\"Entfernt:\", count)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gef端llt: 41\n",
      "Entfernt: 4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from classes.feature_factory import FeatureFactory\n",
    "\n",
    "# Trainingsdaten & Testdaten laden\n",
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "test_df = pd.read_csv(\"~/Downloads/test_segments/test_0000.csv\")\n",
    "\n",
    "# Beispiel f端r die Verwendung FeatureFactory\n",
    "factory = FeatureFactory(train_df, test_df)\n",
    "\n",
    "n_sfa_components = 4\n",
    "sfa_control_areas = [1, 2]\n",
    "sfa_degree = 2\n",
    "\n",
    "factory.add_corrected_demand_feature()\n",
    "\n",
    "selected_sfa_features = [\"Demand\", \"correction\", \"correctionEcho\",\n",
    "                            \"FRCE\", \"LFCInput\", \"aFRRactivation\", \"aFRRrequest\"]\n",
    "\n",
    "for sfa_control_area in sfa_control_areas:\n",
    "    factory.add_SFA(\n",
    "        n_sfa_components,\n",
    "        selected_sfa_features,\n",
    "        poly_degree=sfa_degree,\n",
    "        control_area=sfa_control_area,\n",
    "        batch_size=100,\n",
    "        cascade_length=1,\n",
    "    )\n",
    "\n",
    "factory.add_time_features()\n",
    "factory.add_rolling_features(window_size=3)\n",
    "# factory.add_rolling_features_by_control_area(window_size=3)\n",
    "factory.add_ratio_and_diff_features()\n",
    "factory.add_aFRR_activation_request_ratio()\n",
    "factory.add_FRCE_LFCInput_difference()\n",
    "factory.add_participation_state()\n",
    "factory.add_demand_FRCE_interaction()\n",
    "\n",
    "# Features\n",
    "# New features beginn with 'day', ...\n",
    "features = [\n",
    "    \"Demand\",\n",
    "    \"correction\",\n",
    "    \"correctedDemand\",\n",
    "    \"FRCE\",\n",
    "    \"controlBandPos\",\n",
    "    \"controlBandNeg\",\n",
    "    \"LFCInput\",\n",
    "    \"aFRRactivation\",\n",
    "    \"aFRRrequest\",\n",
    "    \"participationCMO\",\n",
    "    \"participationIN\",\n",
    "    \"correctionEcho\",\n",
    "    \"BandLimitedCorrectedDemand\",\n",
    "    \"controlArea\",\n",
    "    \"hour\",\n",
    "    \"day\",\n",
    "    \"weekday\",\n",
    "    \"month\",\n",
    "    # \"Demand_RollingMean\",\n",
    "    # \"Demand_RollingStd\",\n",
    "    \"Demand_CorrectedDemand_Ratio\",\n",
    "    \"Demand_CorrectedDemand_Diff\",\n",
    "    \"aFRR_Activation_Request_Ratio\",\n",
    "    \"FRCE_LFCInput_Diff\",\n",
    "    \"Participation_State\",\n",
    "    \"Demand_FRCE_Interaction\",\n",
    "]  # , 'corrected_demand_diff']\n",
    "\n",
    "for sfa_control_area in sfa_control_areas:\n",
    "    sfa_features = [\n",
    "        f\"sfa{c}_{sfa_control_area}\" for c in range(n_sfa_components)]\n",
    "features = features + sfa_features\n",
    "\n",
    "X_train = factory.train_data[features]\n",
    "X_test = factory.test_data[features]\n",
    "\n",
    "X_train.isna().sum()\n",
    "\n",
    "# Scaler\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "# Isolation Forest Modell initialisieren und trainieren\n",
    "model = IsolationForest(\n",
    "    n_estimators=32, contamination=\"auto\", random_state=42)\n",
    "model.fit(X_train_normalized)\n",
    "\n",
    "# Anomalien auf Testdaten vorhersagen und anzeigen\n",
    "test_df[\"anomaly\"] = model.predict(X_test_normalized)\n",
    "\n",
    "# Konvertiere Anomalie-Vorhersagen: -1 (Anomalie) wird zu 1 und 1 (normal) wird zu 0\n",
    "test_df[\"anomaly\"] = test_df[\"anomaly\"].apply(\n",
    "    lambda x: 1 if x == -1 else 0)\n",
    "\n",
    "df_filled = fill_anomalies(\n",
    "    test_df.copy(), window_size=10, threshold=4, loops=2)\n",
    "submission_df = remove_anomalies(\n",
    "    df_filled.copy(), window_size=5, threshold=4)\n",
    "\n",
    "#submission_df = submission_df[[\"id\", \"anomaly\"]]\n",
    "#submission_df.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['shifted_anomaly'] = submission_df['anomaly'].shift(1)\n",
    "submission_df['change'] = submission_df['anomaly'] != submission_df['shifted_anomaly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes_df = submission_df[submission_df['change']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = []\n",
    "for i in range(len(changes_df) - 1):\n",
    "    start_time = changes_df.iloc[i]['Datum_Uhrzeit_CET']\n",
    "    end_time = changes_df.iloc[i + 1]['Datum_Uhrzeit_CET']\n",
    "    start_anomaly = changes_df.iloc[i]['anomaly']\n",
    "    end_anomaly = changes_df.iloc[i + 1]['anomaly']\n",
    "    \n",
    "    # Assuming anomaly switches from 0 to 1 and then back from 1 to 0\n",
    "    if start_anomaly == 1 and end_anomaly == 0:\n",
    "        windows.append((start_time, end_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Timestamp('2023-05-13 00:13:08'), Timestamp('2023-05-13 00:24:56'))\n",
      "(Timestamp('2023-05-13 00:31:12'), Timestamp('2023-05-13 00:56:16'))\n",
      "(Timestamp('2023-05-13 01:59:08'), Timestamp('2023-05-13 01:59:32'))\n"
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "for window in windows:\n",
    "    print(window)\n",
    "    result.append(\n",
    "        { \n",
    "            \"from_name\": \"label\",\n",
    "            \"to_name\": \"ts\",\n",
    "            \"type\": \"timeserieslabels\",\n",
    "            \"value\": {\n",
    "                \"start\": str(window[0]),  \n",
    "                \"end\": str(window[1]),    \n",
    "                \"timeserieslabels\": [\"anomaly\"] \n",
    "            \n",
    "            }\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 11,\n",
       " 'model_version': '1',\n",
       " 'created_ago': '0\\xa0minutes',\n",
       " 'result': [{'from_name': 'label',\n",
       "   'to_name': 'ts',\n",
       "   'type': 'timeserieslabels',\n",
       "   'value': {'start': '2023-05-13 00:13:08',\n",
       "    'end': '2023-05-13 00:24:56',\n",
       "    'timeserieslabels': ['anomaly']}},\n",
       "  {'from_name': 'label',\n",
       "   'to_name': 'ts',\n",
       "   'type': 'timeserieslabels',\n",
       "   'value': {'start': '2023-05-13 00:31:12',\n",
       "    'end': '2023-05-13 00:56:16',\n",
       "    'timeserieslabels': ['anomaly']}},\n",
       "  {'from_name': 'label',\n",
       "   'to_name': 'ts',\n",
       "   'type': 'timeserieslabels',\n",
       "   'value': {'start': '2023-05-13 01:59:08',\n",
       "    'end': '2023-05-13 01:59:32',\n",
       "    'timeserieslabels': ['anomaly']}}],\n",
       " 'score': 0.0,\n",
       " 'cluster': None,\n",
       " 'neighbors': None,\n",
       " 'mislabeling': 0.0,\n",
       " 'created_at': '2024-01-23T23:16:27.377680Z',\n",
       " 'updated_at': '2024-01-23T23:16:27.377709Z',\n",
       " 'task': 2,\n",
       " 'project': 1}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.create_prediction(2, \n",
    "                            result=result, \n",
    "                            model_version='1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
